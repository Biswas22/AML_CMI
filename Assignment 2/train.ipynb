{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import mlflow\n",
    "random.seed(1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading in the train, test and validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = './data/train.csv'\n",
    "path_val = './data/validation.csv'\n",
    "path_test = './data/test.csv'\n",
    "path_mod_df = './data/mod_df.csv'\n",
    "\n",
    "train_df = pd.read_csv(path_train)\n",
    "val_df = pd.read_csv(path_val)\n",
    "test_df = pd.read_csv(path_test)\n",
    "raw_data = pd.read_csv(path_mod_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the response from 'spam' and 'ham' to 0 and 1 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['y_train'] = train_df['y_train'].map({'ham': 1, 'spam': 0})\n",
    "val_df['y_val'] = val_df['y_val'].map({'ham': 1, 'spam': 0})\n",
    "test_df['y_test'] = test_df['y_test'].map({'ham': 1, 'spam': 0})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the bag of words transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7340\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_df.X_train)\n",
    "\n",
    "bow_transformer = vectorizer.vocabulary_\n",
    "print(len(bow_transformer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting all the data to be used into bag of words form**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4514, 7340) (502, 7340) (558, 7340)\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizer.transform(train_df.X_train)\n",
    "X_val = vectorizer.transform(val_df.X_val)\n",
    "X_test = vectorizer.transform(test_df.X_test)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the tf-idf transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting the data into tf-idf form**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4514, 7340) (502, 7340) (558, 7340)\n"
     ]
    }
   ],
   "source": [
    "tfidf_X_train = tfidf_transformer.transform(X_train)\n",
    "tfidf_X_val = tfidf_transformer.transform(X_val)\n",
    "tfidf_X_test = tfidf_transformer.transform(X_test)\n",
    "\n",
    "print(tfidf_X_train.shape, tfidf_X_val.shape, tfidf_X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial Naive Bayes Model based on tf-idf tokenizer**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a function to create the spam detection model and compute the evaluation metrics for the predicted values based on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNB_model(alp):\n",
    "    spam_detection_model = MultinomialNB(alpha = alp).fit(tfidf_X_train, train_df.y_train)\n",
    "    test_predictions = spam_detection_model.predict(tfidf_X_test)\n",
    "\n",
    "    acc_sc = accuracy_score(test_df.y_test, test_predictions)\n",
    "    \n",
    "    #Computing Precision and Recall\n",
    "    precision, recall, thresholds = precision_recall_curve(test_df.y_test, test_predictions)\n",
    "    # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "    aupcr = auc(recall, precision)\n",
    "    \n",
    "    #print(\"The AUPCR score is:\",aupcr)\n",
    "    return [acc_sc, aupcr]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Model based on tf-idf tokenizer**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the spam detection model and computing the evaluation metrics for the predicted values based on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Log_model(C):\n",
    "    spam_detection_model_2 = LogisticRegression(C = i)\n",
    "    spam_detection_model_2.fit(tfidf_X_train, train_df.y_train)\n",
    "    test_predictions = spam_detection_model_2.predict(tfidf_X_test)\n",
    "    acc_sc = accuracy_score(test_df.y_test, test_predictions)\n",
    "    \n",
    "    #Computing Precision and Recall\n",
    "    precision, recall, _ = precision_recall_curve(test_df.y_test, test_predictions)\n",
    "    # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "    aupcr = auc(recall, precision)\n",
    "    #print(\"The AUPCR score is:\",aupcr)\n",
    "\n",
    "    return [acc_sc, aupcr]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Classifier Model**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the spam detection model and computing the evaluation metrics for the predicted values based on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC_Model(C):    \n",
    "    spam_detection_model_3 = SVC(C = i)\n",
    "    spam_detection_model_3.fit(tfidf_X_train, train_df.y_train)\n",
    "    test_predictions = spam_detection_model_3.predict(tfidf_X_test)\n",
    "    acc_sc = accuracy_score(test_df.y_test, test_predictions)\n",
    "    \n",
    "    #Computing Precision and Recall\n",
    "    precision, recall, _ = precision_recall_curve(test_df.y_test, test_predictions)\n",
    "    # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "    aupcr = auc(recall, precision)\n",
    "    #print(\"The AUPCR score is:\",aupcr)\n",
    "\n",
    "    return [acc_sc, aupcr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "'MLFlow_Logs\\mlruns' does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m mlflow\u001b[39m.\u001b[39mset_tracking_uri(\u001b[39m'\u001b[39m\u001b[39mMLFlow_Logs\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmlruns\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[39m#set experiment\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m mlflow\u001b[39m.\u001b[39;49mset_experiment(\u001b[39m'\u001b[39;49m\u001b[39mSMS Spam Classification Model Evaluation\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\env_py39\\lib\\site-packages\\mlflow\\tracking\\fluent.py:112\u001b[0m, in \u001b[0;36mset_experiment\u001b[1;34m(experiment_name, experiment_id)\u001b[0m\n\u001b[0;32m    110\u001b[0m client \u001b[39m=\u001b[39m MlflowClient()\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m experiment_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     experiment \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mget_experiment_by_name(experiment_name)\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m experiment:\n\u001b[0;32m    114\u001b[0m         _logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    115\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExperiment with name \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m does not exist. Creating a new experiment.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    116\u001b[0m             experiment_name,\n\u001b[0;32m    117\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\env_py39\\lib\\site-packages\\mlflow\\tracking\\client.py:451\u001b[0m, in \u001b[0;36mMlflowClient.get_experiment_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_experiment_by_name\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Experiment]:\n\u001b[0;32m    421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[39m    Retrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m        Lifecycle_stage: active\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mget_experiment_by_name(name)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\env_py39\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:220\u001b[0m, in \u001b[0;36mTrackingServiceClient.get_experiment_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_experiment_by_name\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[0;32m    216\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39m    :param name: The experiment name.\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m    :return: :py:class:`mlflow.entities.Experiment`\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mget_experiment_by_name(name)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\env_py39\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:310\u001b[0m, in \u001b[0;36mFileStore.get_experiment_by_name\u001b[1;34m(self, experiment_name)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpagination_wrapper_func\u001b[39m(number_to_get, next_page_token):\n\u001b[0;32m    303\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_experiments(\n\u001b[0;32m    304\u001b[0m         view_type\u001b[39m=\u001b[39mViewType\u001b[39m.\u001b[39mACTIVE_ONLY,\n\u001b[0;32m    305\u001b[0m         max_results\u001b[39m=\u001b[39mnumber_to_get,\n\u001b[0;32m    306\u001b[0m         filter_string\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mname = \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mexperiment_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    307\u001b[0m         page_token\u001b[39m=\u001b[39mnext_page_token,\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m experiments \u001b[39m=\u001b[39m get_results_from_paginated_fn(\n\u001b[0;32m    311\u001b[0m     paginated_fn\u001b[39m=\u001b[39;49mpagination_wrapper_func,\n\u001b[0;32m    312\u001b[0m     max_results_per_page\u001b[39m=\u001b[39;49mSEARCH_MAX_RESULTS_THRESHOLD,\n\u001b[0;32m    313\u001b[0m     max_results\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    314\u001b[0m )\n\u001b[0;32m    315\u001b[0m \u001b[39mreturn\u001b[39;00m experiments[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(experiments) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\env_py39\\lib\\site-packages\\mlflow\\utils\\__init__.py:248\u001b[0m, in \u001b[0;36mget_results_from_paginated_fn\u001b[1;34m(paginated_fn, max_results_per_page, max_results)\u001b[0m\n\u001b[0;32m    246\u001b[0m     page_results \u001b[39m=\u001b[39m paginated_fn(num_to_get, next_page_token)\n\u001b[0;32m    247\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 248\u001b[0m     page_results \u001b[39m=\u001b[39m paginated_fn(max_results_per_page, next_page_token)\n\u001b[0;32m    249\u001b[0m all_results\u001b[39m.\u001b[39mextend(page_results)\n\u001b[0;32m    250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(page_results, \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m page_results\u001b[39m.\u001b[39mtoken:\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\env_py39\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:303\u001b[0m, in \u001b[0;36mFileStore.get_experiment_by_name.<locals>.pagination_wrapper_func\u001b[1;34m(number_to_get, next_page_token)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpagination_wrapper_func\u001b[39m(number_to_get, next_page_token):\n\u001b[1;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearch_experiments(\n\u001b[0;32m    304\u001b[0m         view_type\u001b[39m=\u001b[39;49mViewType\u001b[39m.\u001b[39;49mACTIVE_ONLY,\n\u001b[0;32m    305\u001b[0m         max_results\u001b[39m=\u001b[39;49mnumber_to_get,\n\u001b[0;32m    306\u001b[0m         filter_string\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mname = \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mexperiment_name\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    307\u001b[0m         page_token\u001b[39m=\u001b[39;49mnext_page_token,\n\u001b[0;32m    308\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\env_py39\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:274\u001b[0m, in \u001b[0;36mFileStore.search_experiments\u001b[1;34m(self, view_type, max_results, filter_string, order_by, page_token)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39mif\u001b[39;00m max_results \u001b[39m>\u001b[39m SEARCH_MAX_RESULTS_THRESHOLD:\n\u001b[0;32m    268\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    269\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid value for max_results. It must be at most \u001b[39m\u001b[39m{\u001b[39;00mSEARCH_MAX_RESULTS_THRESHOLD\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    270\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but got \u001b[39m\u001b[39m{\u001b[39;00mmax_results\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    271\u001b[0m         INVALID_PARAMETER_VALUE,\n\u001b[0;32m    272\u001b[0m     )\n\u001b[1;32m--> 274\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_root_dir()\n\u001b[0;32m    275\u001b[0m experiment_ids \u001b[39m=\u001b[39m []\n\u001b[0;32m    276\u001b[0m \u001b[39mif\u001b[39;00m view_type \u001b[39m==\u001b[39m ViewType\u001b[39m.\u001b[39mACTIVE_ONLY \u001b[39mor\u001b[39;00m view_type \u001b[39m==\u001b[39m ViewType\u001b[39m.\u001b[39mALL:\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\env_py39\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:173\u001b[0m, in \u001b[0;36mFileStore._check_root_dir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39mRun checks before running directory operations.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_directory):\n\u001b[1;32m--> 173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m does not exist.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_directory)\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_directory(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_directory):\n\u001b[0;32m    175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not a directory.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_directory)\n",
      "\u001b[1;31mException\u001b[0m: 'MLFlow_Logs\\mlruns' does not exist."
     ]
    }
   ],
   "source": [
    "from  mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "#log into MLflow\n",
    "\n",
    "#Set storage directory\n",
    "mlflow.set_tracking_uri('MLFlow_Logs\\mlruns')\n",
    "\n",
    "#set experiment\n",
    "mlflow.set_experiment('SMS Spam Classification Model Evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('SMS Spam Classification Model Evaluation')\n",
    "#Running the models and logging the runs with MLFlow\n",
    "md_name = \"Multinomial Naive Bayes\" \n",
    "for i in np.arange(0.05, 2.25, 0.25):\n",
    "    with mlflow.start_run() as run: #inside brackets run_name='test'\n",
    "        #Log parameters\n",
    "        mlflow.log_param(\"Model\",md_name)\n",
    "        mlflow.log_param(\"Alpha\",i)\n",
    "        #Running the model\n",
    "        model_metrics = MNB_model(i)\n",
    "        #Logging metrics\n",
    "        mlflow.log_metric(\"Accuracy\", model_metrics[0])\n",
    "        mlflow.log_metric(\"AUPCR\", model_metrics[1])\n",
    "\n",
    "md_name = \"Logistic Regression\"\n",
    "for i in [0.1, 0.5, 1, 10, 20, 50, 100]:\n",
    "    with mlflow.start_run() as run: \n",
    "        #Log parameters\n",
    "        mlflow.log_param(\"Model\",md_name)\n",
    "        mlflow.log_param(\"C\",i)\n",
    "        #Running the model\n",
    "        model_metrics = Log_model(i)\n",
    "        #Logging metrics\n",
    "        mlflow.log_metric(\"Accuracy\", model_metrics[0])\n",
    "        mlflow.log_metric(\"AUPCR\", model_metrics[1])\n",
    "\n",
    "\n",
    "md_name = \"Support Vector Classifier\"\n",
    "for i in [0.1, 0.5, 1, 10, 20, 50, 100]:\n",
    "    with mlflow.start_run() as run: \n",
    "        #Log parameters\n",
    "        mlflow.log_param(\"Model\",md_name)\n",
    "        mlflow.log_param(\"Alpha\",i)\n",
    "        #Running the model\n",
    "        model_metrics = MNB_model(i)\n",
    "        #Logging metrics\n",
    "        mlflow.log_metric(\"Accuracy\", model_metrics[0])\n",
    "        mlflow.log_metric(\"AUPCR\", model_metrics[1])\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9839ce3c6acaca560491e1b41f8b46d426659617553cc8a88a5826e3aaa30400"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
