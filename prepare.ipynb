{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325aeb6d",
   "metadata": {},
   "source": [
    "**Importing the required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e69d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import regex as re\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet \n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b179c1c6",
   "metadata": {},
   "source": [
    "**Reading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f6b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/SMSSpamCollection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0ac34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(path):\n",
    "    messages = [line.rstrip() for line in open(path)]\n",
    "    print(\"No. of rows of data =\",len(messages))\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e19b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    messages = pd.read_csv(path, sep='\\t', quoting=csv.QUOTE_NONE,\n",
    "                           names=[\"label\", \"message\"])\n",
    "    print(\"No. of rows of data\",len(messages))\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92f2925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows of data = 5574\n",
      "0 ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "1 ham\tOk lar... Joking wif u oni...\n",
      "2 spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "3 ham\tU dun say so early hor... U c already then say...\n",
      "4 ham\tNah I don't think he goes to usf, he lives around here though\n",
      "5 spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, Â£1.50 to rcv\n",
      "6 ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
      "7 ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "8 spam\tWINNER!! As a valued network customer you have been selected to receivea Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "9 spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n"
     ]
    }
   ],
   "source": [
    "#Calling the function read_txt to read the data from the provided directory path\n",
    "data_txt = read_txt(path)\n",
    "\n",
    "#Printing the 1st 10 rows of the data\n",
    "for idx, info in enumerate(data_txt[:10]):\n",
    "    print(idx, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "040bf041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows of data 5574\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calling the function read_csv to read the data as pandas dataframe from the provided directory path\n",
    "data_df = read_csv(path)\n",
    "\n",
    "#Printing the 1st 10 rows of the data\n",
    "data_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d51bff",
   "metadata": {},
   "source": [
    "**Preprocessing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82b7ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to split the words into tokens\n",
    "def split_into_tokens(data):\n",
    "    tokenized_words = []\n",
    "    regex=r\"\\w+\"\n",
    "    \n",
    "    for i in range(len(data.message)):\n",
    "        tokenized_words.append(re.findall(regex, data.message[i]))\n",
    "        \n",
    "    return tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90030cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to perform lematization and stopword removal\n",
    "def lemmatize(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        temp = []\n",
    "\n",
    "        for j in range(len(data[i])):\n",
    "        \n",
    "            if data[i][j].lower() in stop_words:\n",
    "                continue\n",
    "            \n",
    "            elif data[i][j] in string.punctuation:\n",
    "                continue\n",
    "            \n",
    "            else:\n",
    "                temp.append(str(lemmatizer.lemmatize(data[i][j]).lower()))\n",
    "\n",
    "        lemmatized_words.append(temp)             \n",
    "\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a9e4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the required functions for pre-processing\n",
    "token_words = split_into_tokens(data_df)\n",
    "processed_words = lemmatize(token_words)\n",
    "\n",
    "data_df['processed_message'] = processed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ebb46",
   "metadata": {},
   "source": [
    "**Performing train, test and vaidation split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30fe3cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-validation and test split\n",
    "train_test_split_size = 0.1\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(data_df.processed_message, data_df.label, test_size = train_test_split_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff28f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and Validation split\n",
    "train_val_split_size = 0.1\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = train_val_split_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b10bb8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the splitted dataframes\n",
    "train_df = pd.DataFrame({'X_train': X_train,'y_train': y_train})\n",
    "val_df = pd.DataFrame({'X_val': X_val,'y_val': y_val})\n",
    "test_df = pd.DataFrame({'X_test': X_test,'y_test': y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a373207",
   "metadata": {},
   "source": [
    "**Storing the splits and the modified data frame in csv format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1301dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./data/train.csv',index = False)\n",
    "val_df.to_csv('./data./validation.csv',index = False)\n",
    "test_df.to_csv('./data/test.csv',index = False)\n",
    "data_df.to_csv('./data/mod_df.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
